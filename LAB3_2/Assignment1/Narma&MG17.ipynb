{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Assignment 1.1: NARMA10 task with ESN\n",
    "This task consists of predicting the output of a 10th order non-linear autoregressive moving average (NARMA) system.\n",
    "Given the input value x(t), the task is to predict the corresponding value of y(t).\n",
    "* Import the dataset from the .csv file “NARMA10.csv” (available on the Moodle platform), where the first row represents the input, and the second row represents the target output. Different columns represent different time-steps.\n",
    "* Split the data into training (the first 5000 time steps), and test set (remaining time steps). Note that for model selection you will use the data in the training set, with a further split in training (first 4000 samples) and validation (last 1000 samples).\n",
    "* For the sake of problem understanding, you can try to first visualize the time-series data (using the matplotlib library in Python or the plot command in Matlab)\n",
    "\n",
    "1) Implement from the scratch the code required to initialize, run, train and evaluate an Echo State Network (in NumPy or Matlab). Your implementation should take into consideration relevant hyper-parametrization of the neural network (e.g., number of reservoir neurons, spectral radius, etc.)\n",
    "\n",
    "2) Perform a model selection (e.g., by grid search or random search) on the values of the hyper-parameters identified in the previous point. Select on the validation set the best hyper-parametrization, as the one with the smallest Mean Squared Error (MSE).\n",
    "\n",
    "3) Train the ESN model with the selected hyper-parametrization on the whole training set, and evaluate its MSE on the training set and on the test set.\n",
    "\n",
    "\n",
    "NOTE: For each hyper-parameterization that you consider, the performance (on training, validation and test sets) should be averaged over a number of reservoir guesses, i.e. different random instances of ESNs with the same values of the hyper-parameters (and potentially different random weights)\n",
    "\n",
    "# Bonus-track Assignment 1.2: Mackey-Glass 17 task with ESN\n",
    "\n",
    "Solve the same assignment as in the previous exercise, this time referring to the Mackey-Glass (MG) 17 task (see details on this task in th  previous lab assignment file)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
