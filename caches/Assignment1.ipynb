{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Assignment 1.1: NARMA10 task with ESN\n",
    "This task consists of predicting the output of a 10th order non-linear autoregressive moving average (NARMA) system.\n",
    "Given the input value x(t), the task is to predict the corresponding value of y(t).\n",
    "* Import the dataset from the .csv file “NARMA10.csv” (available on the Moodle platform), where the first row represents the input, and the second row represents the target output. Different columns represent different time-steps.\n",
    "* Split the data into training (the first 5000 time steps), and test set (remaining time steps). Note that for model selection you will use the data in the training set, with a further split in training (first 4000 samples) and validation (last 1000 samples).\n",
    "* For the sake of problem understanding, you can try to first visualize the time-series data (using the matplotlib library in Python or the plot command in Matlab)\n",
    "\n",
    "1) Implement from the scratch the code required to initialize, run, train and evaluate an Echo State Network (in NumPy or Matlab). Your implementation should take into consideration relevant hyper-parametrization of the neural network (e.g., number of reservoir neurons, spectral radius, etc.)\n",
    "\n",
    "2) Perform a model selection (e.g., by grid search or random search) on the values of the hyper-parameters identified in the previous point. Select on the validation set the best hyper-parametrization, as the one with the smallest Mean Squared Error (MSE).\n",
    "\n",
    "3) Train the ESN model with the selected hyper-parametrization on the whole training set, and evaluate its MSE on the training set and on the test set.\n",
    "\n",
    "\n",
    "NOTE: For each hyper-parameterization that you consider, the performance (on training, validation and test sets) should be averaged over a number of reservoir guesses, i.e. different random instances of ESNs with the same values of the hyper-parameters (and potentially different random weights)\n",
    "\n",
    "# Bonus-track Assignment 1.2: Mackey-Glass 17 task with ESN\n",
    "\n",
    "Solve the same assignment as in the previous exercise, this time referring to the Mackey-Glass (MG) 17 task (see details on this task in th  previous lab assignment file)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from numpy import ndarray,vstack\n",
    "from typing import Tuple\n",
    "from itertools import product\n",
    "from numpy.linalg import pinv\n",
    "\n",
    "from LAB3_1.utils import show_split, make_sequence, show_result\n",
    "from LAB3_2.LatentESN import EchoStateNetwork"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class ESN_seq2seq:\n",
    "\n",
    "    def __init__(self, input_size: int, output_size: int, hidden_dim: int, omega: Tuple[float, float],\n",
    "                 spectral_radius: float, lambda_: float, dt_type: str):\n",
    "        \"\"\"\n",
    "        Model based on Echo State network used into \"Sequence to Sequence\" scenario.\n",
    "\n",
    "        :param input_size: Input dimension\n",
    "        :param output_size: Output dimension\n",
    "        :param hidden_dim: hidden dimension\n",
    "        :param omega: Scaling factor of input matrix and bias\n",
    "        :param spectral_radius: Desiderata spectral radius\n",
    "        :param lambda_: Tikhonov regularization parameter\n",
    "        :param transient: Number of initial elements to discard\n",
    "        \"\"\"\n",
    "        self.lambda_ = lambda_  # Tikhonov regularization\n",
    "        self.b_steps = input_size  # Back steps\n",
    "        self.dt_type = dt_type  # Type of task (used to in \"make_sequence\")\n",
    "\n",
    "        # Latent Echo state network (untrained)\n",
    "        self.latent_esn = EchoStateNetwork(input_size, hidden_dim, omega, spectral_radius)\n",
    "\n",
    "        # Readout (trained)\n",
    "        self.Wo = np.random.uniform(-1, 1, (hidden_dim, output_size))\n",
    "\n",
    "    def fit(self, dt: ndarray, transient:int) -> Tuple[float, ndarray]:\n",
    "        \"\"\"\n",
    "        Fit the model using the input, the target.\n",
    "        First, it calculates the hidden states, which are used to fit the readout;\n",
    "        finally, we return the loss between the output and target with a trained model\n",
    "        and the last hidden state.\n",
    "        \"\"\"\n",
    "        x, y = make_sequence(dt, self.b_steps, self.dt_type, to_numpy=True)\n",
    "\n",
    "        # Perform the hidden states (without a given initial state)\n",
    "        h_states = self.latent_esn(x)\n",
    "        # Discard the transient\n",
    "        h_states, y = h_states[transient:], y[transient:]\n",
    "        # Fit directly the readout\n",
    "        self.Wo = pinv(\n",
    "            h_states.T @ h_states + self.lambda_ * np.eye(h_states.shape[1])) @ h_states.T @ y\n",
    "\n",
    "        y_pred = h_states @ self.Wo\n",
    "        return self.MSE(y, y_pred), h_states[-1]\n",
    "\n",
    "    @staticmethod\n",
    "    def MSE(y: ndarray, y_pred: ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Mean square error\n",
    "        :param y: Target\n",
    "        :param y_pred: Predicted target\n",
    "        \"\"\"\n",
    "        return np.power((y - y_pred), 2).mean()\n",
    "\n",
    "    def validate(self, dt: ndarray, h_0: ndarray = None):\n",
    "        \"\"\"\n",
    "        Given a dataset, it builds the sequence of train and performs the prediction.\n",
    "        It returns loss, the output, the last hidden state and the target\n",
    "        \"\"\"\n",
    "        x, y = make_sequence(dt, self.b_steps, self.dt_type, to_numpy=True)\n",
    "        return self.predict(x, y, h_0) + (y,)\n",
    "\n",
    "    def predict(self, x: ndarray, y: ndarray = None, h0: ndarray = None):\n",
    "        \"\"\"\n",
    "        Perform the forward pass with initially hidden state, if provided.\n",
    "        If it provided the target, it performs also the loss\n",
    "        :param x: Input signal\n",
    "        :param y: Target signal\n",
    "        :param h0: Initially hidden state\n",
    "        \"\"\"\n",
    "        # Perform the hidden states\n",
    "        hidden_states = self.latent_esn(x, h0)  # [steps, input_size]\n",
    "        # Output signal\n",
    "        y_pred = hidden_states @ self.Wo\n",
    "\n",
    "        loss = None\n",
    "        if y is not None:\n",
    "            loss = self.MSE(y, y_pred)\n",
    "\n",
    "        output = hidden_states[-1], y_pred\n",
    "        return ((loss,) + output) if loss is not None else output"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Grid-search function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class GridSearch:\n",
    "\n",
    "    def __init__(self, parameters_grid:dict, tr:ndarray, dev:ndarray, dt_type:str):\n",
    "\n",
    "        all_configs = [dict(zip(parameters_grid.keys(), configs)) for configs in product(*parameters_grid.values())]\n",
    "\n",
    "        print(\"Number of configurations to try: \",len(all_configs))\n",
    "        \"\"\"\n",
    "        Returns the performance in each configuration:\n",
    "            rank = a list of results for each configuration\n",
    "            loss = training loss history of the best model\n",
    "        \"\"\"\n",
    "        rank = self.run(tr, dev, all_configs, dt_type)\n",
    "\n",
    "        # we sort by validation loss\n",
    "        rank = sorted(rank, key=lambda conf: conf[2])\n",
    "\n",
    "        print(\"\\nThe best solution in \", rank[0])\n",
    "        self.best_config = rank[0][0]\n",
    "\n",
    "    @staticmethod\n",
    "    def run(tr:ndarray, dev:ndarray, configs:list, dt_type:str):\n",
    "        \"\"\"\n",
    "        In the grid search, we explore all configurations provided and try to find the best\n",
    "        hyperparameter configuration using the training set to train the model and the validation\n",
    "        set to compare the performance among all models instantiated by configurations.\n",
    "        \"\"\"\n",
    "\n",
    "        rank = [] # keep in track the configuration and the corresponding performance\n",
    "\n",
    "        # we save the best trained model and the training loss history during the epochs\n",
    "        best_dev_loss = sys.maxsize\n",
    "\n",
    "        max_try = 3 # Number of trials for each configuration\n",
    "\n",
    "        for config in tqdm(configs): # try each configuration\n",
    "\n",
    "            # With the same hyperparameter, we perform 3 different \"trainings\" and\n",
    "            # we evaluate the configuration as average of this training\n",
    "            losses = multiple_train(tr, config, dt_type, [dev])\n",
    "            rank.append((config, round(losses[0], 6), round(losses[1], 6)))\n",
    "\n",
    "            # we keep the best model\n",
    "            if best_dev_loss > losses[1]:\n",
    "                best_dev_loss = losses[1]\n",
    "\n",
    "        return rank\n",
    "\n",
    "def multiple_train(tr:ndarray, config:dict, dt_type:str,\n",
    "                   dts:list[ndarray]=None, return_model:bool=False):\n",
    "    \"\"\"\n",
    "    Perform the training different time, and we keep the average loss\n",
    "    :param tr: Training dataset using for fitting the readout\n",
    "    :param config: Hyperparameters\n",
    "    :param dt_type: Type of input data (NARMA10 or MK17)\n",
    "    :param dts: other datasets to evaluate\n",
    "    :param return_model: if true return the model\n",
    "    \"\"\"\n",
    "    trains, trainer = [], None\n",
    "    for _ in range(3):\n",
    "        trainer = ESN_seq2seq(config[\"b_steps\"], 1,\n",
    "                              hidden_dim=config[\"units\"],\n",
    "                              omega=config[\"omega\"],\n",
    "                              spectral_radius=config[\"spectral\"],\n",
    "                              lambda_=config[\"lambda\"],\n",
    "                              dt_type=dt_type)\n",
    "        losses = []\n",
    "        loss_train, last_hidden = trainer.fit(tr, transient=config[\"transient\"])\n",
    "        losses.append(loss_train)\n",
    "        if dts is not None:\n",
    "            for dt in dts:\n",
    "                loss, last_hidden, _, _ =  trainer.validate(dt, last_hidden)\n",
    "                losses.append(loss)\n",
    "        trains.append(losses)\n",
    "\n",
    "    trains = np.array(trains).mean(axis=0)\n",
    "    return (trains, trainer) if return_model else trains\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Retrieve the datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "source1 = pd.read_csv(\"./../sources/NARMA10.csv\", header=None).T.to_numpy()\n",
    "source2 = pd.read_csv(\"./../sources/MG17.csv\", header=None).T.to_numpy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## NARMA10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hold-out"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tr_dataset, dev_dataset, ts_dataset = source1[:4000], source1[4000:5000], source1[5000:]\n",
    "# Although is not much representative, we plot the time target\n",
    "show_split(tr_dataset, dev_dataset, ts_dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Grid search"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "json_dictionary = {}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ranges_to_explore = {\n",
    "    \"b_steps\": [1],\n",
    "    \"units\": [50, 100, 200],\n",
    "    \"omega\": [(0.3, 0.3), (0.5, 0.5)],\n",
    "    \"spectral\": [0.8, 0.9],\n",
    "    \"transient\": [50, 100],\n",
    "    \"lambda\":[1e-4, 1e-5]\n",
    "}\n",
    "\n",
    "gs = GridSearch(ranges_to_explore, tr_dataset, dev_dataset, \"NARMA10\")\n",
    "best_config = gs.best_config\n",
    "\n",
    "json_dictionary[\"best_config\"] = best_config"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tr_vl_ts_loss = multiple_train(tr_dataset, best_config, \"NARMA10\", [dev_dataset, ts_dataset])\n",
    "\n",
    "print(\"Train Error\", round(tr_vl_ts_loss[0], 6))\n",
    "print(\"Validation Error\", round(tr_vl_ts_loss[1], 6))\n",
    "print(\"Test Error\", round(tr_vl_ts_loss[2], 6))\n",
    "\n",
    "\n",
    "json_dictionary[\"best_config\"] = best_config\n",
    "json_dictionary[\"Model_evaluation\"] = (\n",
    "    round(tr_vl_ts_loss[0].item(),6),\n",
    "    round(tr_vl_ts_loss[1].item(),6),\n",
    "    round(tr_vl_ts_loss[2].item(),6))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Final retrain with Training and Validation set (with the best configuration)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "final_tr = vstack([tr_dataset,dev_dataset])\n",
    "\n",
    "tr_vl_ts_loss, trainer = multiple_train(final_tr, best_config, \"NARMA10\", [ts_dataset], return_model=True)\n",
    "\n",
    "print(\"Train Error\", round(tr_vl_ts_loss[0], 6))\n",
    "print(\"Test Error\", round(tr_vl_ts_loss[1], 6))\n",
    "\n",
    "json_dictionary[\"Final_retrain\"] = (\n",
    "    round(tr_vl_ts_loss[0].item(),6),\n",
    "    round(tr_vl_ts_loss[1].item(),6))\n",
    "\n",
    "_, hs, tr_pred, tr_y = trainer.validate(final_tr)\n",
    "_, _, ts_pred, ts_y = trainer.validate(ts_dataset, hs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "show_result(tr_pred, tr_y, ts_pred, ts_y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Mackey-Glass 17"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tr_dataset, dev_dataset, ts_dataset = source2[:4000], source2[4000:5000], source2[5000:]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Grid search"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gs = GridSearch(ranges_to_explore, tr_dataset, dev_dataset, \"MG17\")\n",
    "best_config = gs.best_config\n",
    "\n",
    "json_dictionary[\"best_config\"] = best_config"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tr_vl_ts_loss = multiple_train(tr_dataset, best_config, \"MG17\", [dev_dataset, ts_dataset])\n",
    "\n",
    "print(\"Train Error\", round(tr_vl_ts_loss[0], 6))\n",
    "print(\"Validation Error\", round(tr_vl_ts_loss[1], 6))\n",
    "print(\"Test Error\", round(tr_vl_ts_loss[2], 6))\n",
    "\n",
    "\n",
    "json_dictionary[\"best_config\"] = best_config\n",
    "json_dictionary[\"Model_evaluation\"] = (\n",
    "    round(tr_vl_ts_loss[0].item(),6),\n",
    "    round(tr_vl_ts_loss[1].item(),6),\n",
    "    round(tr_vl_ts_loss[2].item(),6))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Final retrain with Training and Validation set (with the best configuration)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "final_tr = vstack([tr_dataset,dev_dataset])\n",
    "\n",
    "tr_vl_ts_loss, trainer = multiple_train(final_tr, best_config, \"MG17\", [ts_dataset], return_model=True)\n",
    "\n",
    "print(\"Train Error\", round(tr_vl_ts_loss[0], 6))\n",
    "print(\"Test Error\", round(tr_vl_ts_loss[1], 6))\n",
    "\n",
    "json_dictionary[\"Final_retrain\"] = (\n",
    "    round(tr_vl_ts_loss[0].item(),6),\n",
    "    round(tr_vl_ts_loss[1].item(),6))\n",
    "\n",
    "_, hs, tr_pred, tr_y = trainer.validate(final_tr)\n",
    "_, _, ts_pred, ts_y = trainer.validate(ts_dataset, hs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "show_result(tr_pred, tr_y, ts_pred, ts_y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.save([best_model.model, gs.tr_loss, tr_pred, tr_y, ts_pred, ts_y],\"caches/TDNN_mackey_glass17.pt\")\n",
    "with open(\"caches/metric_TDNN_mackey_glass17.json\", \"w\") as outfile:\n",
    "    outfile.write(json.dumps(json_dictionary))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
