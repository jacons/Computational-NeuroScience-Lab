{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Bonus-Track Assignment 5: Char RNN\n",
    "Implement a Character RNN, train it to generate sequential data from your favorite author (you can also consider generating lyrics for songs). Experiment using different choices for the RNN-based language model (e.g., LSTM, GRU, RNN, etc.) and temperature for the sampling function.\n",
    "\n",
    "A tutorial on how to start organizing your code is available at\n",
    "https://colab.research.google.com/drive/1WsETcyfV7lGibKG2OojHN5AfzJmNBHT6?usp=sharing\n",
    "\n",
    "The output of the assignment should then consist in the following\n",
    "* The source code. (Please indicate the text you have used to train your model)\n",
    "* The values of the hyperparameters of the model (including the temperature) used in your favorite runs\n",
    "* The generated text in your favorite runs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch import zeros, Tensor,cuda\n",
    "from torch.nn import LSTM, RNN, GRU, Linear, Module, CrossEntropyLoss\n",
    "from torch.optim import AdamW\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.functional import softmax"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T21:51:37.248085200Z",
     "start_time": "2023-06-23T21:51:37.107680200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "gpu = 'cuda' if cuda.is_available() else 'cpu'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T21:51:37.310554600Z",
     "start_time": "2023-06-23T21:51:37.123309400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Builder of Sentences"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "class BuildSentences:\n",
    "    def __init__(self,text_file:str, max_len:int=60, step:int=3):\n",
    "        \"\"\"\n",
    "        :param text_file: file to import\n",
    "        :param max_len: Length of the extracted sequences for training\n",
    "        :param step: We sample a sequence every step character\n",
    "        \"\"\"\n",
    "        self.max_len = max_len\n",
    "        sentences, next_chars = [],[]\n",
    "\n",
    "        text = open(text_file, \"r\", encoding=\"utf-8\").read().lower()\n",
    "\n",
    "        # Build the sub-sequences\n",
    "        for i in range(0, len(text) - max_len, step):\n",
    "            sentences.append(text[i:i+max_len])\n",
    "            next_chars.append(text[i+max_len])\n",
    "\n",
    "        chars = sorted(list(set(text))) # List of unique characters in the corpus\n",
    "        self.char2pos = {char: i for i, char in enumerate(chars)}\n",
    "        self.pos2char = {i: char for i, char in enumerate(chars)}\n",
    "\n",
    "        # Number of sentences and embedding dimension\n",
    "        num_sentences, self.emb_dim = len(sentences), len(chars)\n",
    "\n",
    "        self.x = zeros((num_sentences, max_len, self.emb_dim))\n",
    "        self.y = zeros((num_sentences, self.emb_dim))\n",
    "\n",
    "        for i, sentence in enumerate(sentences):\n",
    "            for t, char in enumerate(sentence):\n",
    "                self.x[i, t, self.char2pos[char]] = 1\n",
    "\n",
    "            self.y[i,self.char2pos[next_chars[i]]] = 1\n",
    "\n",
    "\n",
    "    def chars2hoe(self, chars:str)->Tensor:\n",
    "        \"\"\"\n",
    "        Transform a string into a sequence of OHE vector, given string,\n",
    "        it returns a [1, #char, emb_dim] tensor\n",
    "        :param chars: Sequence of characters\n",
    "        \"\"\"\n",
    "        hoes = zeros((len(chars), self.emb_dim))\n",
    "\n",
    "        for idx, char in enumerate(chars):\n",
    "            hoes[idx,self.char2pos[char]] = 1\n",
    "        return hoes.unsqueeze(0).to(gpu)\n",
    "\n",
    "    def hoes2chars(self, hoes:Tensor)->str:\n",
    "        \"\"\"\n",
    "        Transform a HOE vector or a sequence of HOE vector into string\n",
    "        :param hoes: HOE vector or a sequence of HOE\n",
    "        \"\"\"\n",
    "        string = \"\"\n",
    "        if hoes.ndim == 1: # just one character\n",
    "            return self.pos2char[hoes.nonzero().item()]\n",
    "\n",
    "        elif hoes.ndim == 2: # a sequence of characters\n",
    "            for hoe in hoes:\n",
    "                string += self.pos2char[hoe.nonzero().item()]\n",
    "\n",
    "        return string\n",
    "\n",
    "    def get_sources(self):\n",
    "\n",
    "        return self.x , self.y"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T21:51:37.310554600Z",
     "start_time": "2023-06-23T21:51:37.148007500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Custom Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Loaded into data-loader fot the training phase\n",
    "    \"\"\"\n",
    "    def __init__(self, source_x:Tensor, source_y:Tensor):\n",
    "        self.x, self.y = source_x, source_y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T21:51:37.310554600Z",
     "start_time": "2023-06-23T21:51:37.163613700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Recurrent Neural Network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "class CharRNN(Module):\n",
    "    def __init__(self,module:str, emb_dim:int, hidden:int, layers:int,bi:bool):\n",
    "        super(CharRNN,self).__init__()\n",
    "\n",
    "        if module == \"RNN\":\n",
    "            self.RNN = RNN(emb_dim, hidden, layers, bidirectional=bi, batch_first=True)\n",
    "        elif module == \"LSTM\":\n",
    "            self.RNN = LSTM(emb_dim, hidden, layers, bidirectional=bi,batch_first=True)\n",
    "        elif module == \"GRU\":\n",
    "            self.RNN = GRU(emb_dim, hidden, layers, bidirectional=bi, batch_first=True)\n",
    "\n",
    "        B = 2 if bi else 1\n",
    "        self.readout = Linear(B * hidden, emb_dim)\n",
    "        self.criteria = CrossEntropyLoss()\n",
    "\n",
    "    def forward(self,seq:Tensor, y:Tensor=None):\n",
    "\n",
    "        out, _ = self.RNN(seq)\n",
    "        out =  self.readout(out[:,-1, :]) # take the last hidden step\n",
    "\n",
    "        # Perform the loss if possible\n",
    "        loss = None\n",
    "        if y is not None:\n",
    "            loss = self.criteria(out, y)\n",
    "\n",
    "        # perform the softmax\n",
    "        out = softmax(out.detach(), -1)\n",
    "        return (out, loss) if loss is not None else out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T21:51:37.310554600Z",
     "start_time": "2023-06-23T21:51:37.179259300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "def sample(logits:Tensor, temperature =1.0):\n",
    "    \"\"\"\n",
    "    Softmax with temperature\n",
    "    :param logits: output of the model (probability distribution)\n",
    "    :param temperature: temperature scaling\n",
    "    \"\"\"\n",
    "    logits = np.asarray(logits.cpu().numpy()).astype('float64')\n",
    "    logits = np.log(logits)/temperature\n",
    "    exp_logits = np.exp(logits)\n",
    "    soft_max = exp_logits / np.sum(exp_logits)\n",
    "    return np.random.multinomial(1, soft_max, 1).argmax()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T21:51:37.332693100Z",
     "start_time": "2023-06-23T21:51:37.195126100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "def train(model:Module, dt:Dataset, epoch:int, lr:float):\n",
    "\n",
    "    optimizer = AdamW(model.parameters(),lr)\n",
    "    loader = DataLoader(dt,batch_size=512, shuffle=True)\n",
    "    loss = 0\n",
    "\n",
    "    for i in tqdm(range(epoch)):\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(\"cuda\"), y.to(\"cuda\")\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            _, loss = model(x, y)\n",
    "            loss.backward()\n",
    "            clip_grad_norm_(model.parameters(), 1)\n",
    "            optimizer.step()\n",
    "        if i % 80 == 0:\n",
    "            print(f\"Epoch {i} loss {round(loss.item(), 5)}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T21:51:37.332693100Z",
     "start_time": "2023-06-23T21:51:37.210489Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "def predict_song(model:Module,t:float, input_seq:str, length:int, handler:BuildSentences):\n",
    "\n",
    "    input_seq = handler.chars2hoe(input_seq.lower()).to(\"cuda\")\n",
    "\n",
    "    model_rnn.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(length):\n",
    "\n",
    "            pred_out = model(input_seq)[0]\n",
    "            char_out = handler.pos2char[sample(pred_out, temperature=t)]\n",
    "            char_out_hoe = handler.chars2hoe(char_out)\n",
    "            input_seq = torch.cat((input_seq, char_out_hoe), dim=1)[:,-handler.emb_dim:]\n",
    "            print(char_out, end=\"\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T21:51:37.332693100Z",
     "start_time": "2023-06-23T21:51:37.232413900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "builder = BuildSentences(\"sources/song.txt\")\n",
    "custom_dt = CustomDataset(*builder.get_sources())\n",
    "\n",
    "input_sequence = \"Più di un film, più di un drink, più della marijuana!\"\n",
    "hidden_dim =  128\n",
    "hidden_layers = 2\n",
    "learning_rate = 0.005\n",
    "max_epochs = 150\n",
    "bidirectional = True"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T21:51:37.836844800Z",
     "start_time": "2023-06-23T21:51:37.248085200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Experiements"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### RNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 2/150 [00:00<00:28,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss 3.1217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 81/150 [00:04<00:03, 21.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 loss 0.0445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:07<00:00, 19.85it/s]\n"
     ]
    }
   ],
   "source": [
    "model_rnn = CharRNN(\"RNN\", builder.emb_dim, hidden_dim, hidden_layers, bidirectional).to(gpu)\n",
    "train(model_rnn, custom_dt, max_epochs, learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T21:51:45.415924100Z",
     "start_time": "2023-06-23T21:51:37.836844800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Varying the temperature"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----Temperature 0.2 ----\n",
      "\n",
      "più della miesta co alta\n",
      "pa!\n",
      "più di un frip di sta miss mezza brasiliana\n",
      "dita\n",
      "di un trip di sta miss mezza brasiliana\n",
      "dita\n",
      "di un trip di sta miss mezza brasiliana\n",
      "dita\n",
      "di un trip di sta miss mezza brasiliana\n",
      "dita\n",
      "di un trip di sta miss mezza brasiliana\n",
      "dita\n",
      "di un trip di sta miss mezza brasiliana\n",
      "dita\n",
      "di un trip di sta miss mezza brasiliana\n",
      "dita, niù della coca\n",
      "parnana\n",
      "più di un frip di sta miss \n",
      "\n",
      "----Temperature 0.5 ----\n",
      "\n",
      "più della coca\n",
      "parna\n",
      "più di un frip di sta miss mezza brasiliana\n",
      "dita\n",
      "di un trip di sta miss mezza brasiliana\n",
      "dita\n",
      "di un trip di sta miss mezza brasiliana\n",
      "dita\n",
      "di un trip di sta miss mezza brasiliana!\n",
      "di un fertoran arca\n",
      "più mell’o o alla savonana\n",
      "più di un frip di sta miss mezza brasiliana\n",
      "dita\n",
      "di un trip di sta miss mezza brasiliana\n",
      "dita\n",
      "di un trip di sta miss mezza brasiliana\n",
      "dita\n",
      "di un trip d\n",
      "\n",
      "----Temperature 1.0 ----\n",
      "\n",
      "più della coca\n",
      "parnana!\n",
      "più della mersa an na batarta!\n",
      "più di un fuelta, pie della coca\n",
      "parta\n",
      "più dello mo sn un ta tagna\n",
      "mi pacna hit, più di un furtodatra bazcono scacacana\n",
      "più della messa mazcata\n",
      "scaca\n",
      "più della cocho bcona\n",
      "più dell’ue bell’a, più di un rgie in messo al arta\n",
      "più della me srgpio an rde si sta questa cogacabata\n",
      "più deita cceà\n",
      "pin nellio dell’a cee orcconaca, più della coca\n",
      "parna\n",
      "\n",
      "----Temperature 1.2 ----\n",
      "\n",
      "più della miatamma cantorta\n",
      "più di un frip di sta miss mezza brasiliana\n",
      "dita, nili ellio onon un te to alla hate tame no timed aun rò sia n àuta\n",
      "di un trip di sta miss mezza brasiliana\n",
      "dita, niù della coca\n",
      "parnana!\n",
      "più di un trip di sta miss meiza brasiliana\n",
      "ditua nafmopagna brimidian nall’a e àgnari!\n",
      "più di un fripidiza mell’a cesso alla cabrapicona\n",
      "di più di un fripionan ersi un rj, più di un r\n"
     ]
    }
   ],
   "source": [
    "for temp in [0.2, 0.5, 1.0, 1.2]:\n",
    "    print(f\"\\n----Temperature {temp} ----\")\n",
    "    predict_song(model_rnn, temp, input_sequence, 400, builder)\n",
    "    print(\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T21:51:46.580445700Z",
     "start_time": "2023-06-23T21:51:45.415924100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### LSTM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 2/150 [00:00<00:19,  7.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss 3.49963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 82/150 [00:11<00:09,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 loss 0.55416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:21<00:00,  7.14it/s]\n"
     ]
    }
   ],
   "source": [
    "model_rnn = CharRNN(\"LSTM\", builder.emb_dim, hidden_dim, hidden_layers, bidirectional).to(gpu)\n",
    "train(model_rnn, custom_dt, max_epochs, learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T21:52:07.626389800Z",
     "start_time": "2023-06-23T21:51:46.580445700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Varying the temperature"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----Temperature 0.2 ----\n",
      "\n",
      "più della suita copo ball della ho aprpiù della suita copo ball’a, diammi un brivonona!\n",
      "di un trip di sta miss mezza brasiliana!\n",
      "di un trip di sta miss mezza brasiliana!\n",
      "di un trip di sta miss mezza brasiliana!\n",
      "di un trip di sta miss mezza brasiliana!\n",
      "di un trip di sta miss mezza brasiliana!\n",
      "di un trip di sta miss mezza brasiliana!\n",
      "di un trip di sta miss mezza brasiliana!\n",
      "di un triso briù di ogni\n",
      "\n",
      "----Temperature 0.5 ----\n",
      "\n",
      "più dellla coca\n",
      "più dei giielli edessta sita!\n",
      "più di un trip di sta miss mezza brasiliana!\n",
      "di un trip di sta miss mezza brasiliana!\n",
      "di un trip di sta miss mezza brasiliana!\n",
      "di un trip di sta miss mezza brasiliana!\n",
      "di un trip di sta miss mezza brasiliana!\n",
      "di un trip di sta miss mezza brasiliana!\n",
      "di un trip di sta miss mezza brasiliana!\n",
      "di un tritognie più di ogni banconota, più della coca\n",
      "più dei \n",
      "\n",
      "----Temperature 1.0 ----\n",
      "\n",
      "più di un trip di sta miss mezza brasiliana!\n",
      "di un to iun ove drita!\n",
      "più di un trip di sta mistuo sue mozza!\n",
      "più di un trip di sta miss mezza brasiliana!\n",
      "di un trip di sta miss mezza brasiliana!\n",
      "di un triù di un trip di sta miss mezza brasiliana!\n",
      "di un mj, più dell suessa a capata\n",
      "più di ogni banconota, più della coca\n",
      "più dei giierivesssi a alta!\n",
      "più di ogni banconota, più della coca\n",
      "più dei giie\n",
      "\n",
      "----Temperature 1.2 ----\n",
      "\n",
      "più di un trip di sta mezzo arazazana!\n",
      "più della coca\n",
      "più dei giiere ilisse afrprgni in o edogni brisss meozza brasiliana!\n",
      "di un trod un so (do conancacoca\n",
      "più dellli sucaropo inlli conononza!\n",
      "brro rn me si ola aratizana!\n",
      "di un to ink, più della micordiù dei giieerelsseerassta arozzona!\n",
      "di un trivonditi on brbiù quello a aca\n",
      "più dei giierrisssio copo balli ceelto piauna!\n",
      "di un trid un trip di sta\n"
     ]
    }
   ],
   "source": [
    "for temp in [0.2, 0.5, 1.0, 1.2]:\n",
    "    print(f\"\\n----Temperature {temp} ----\")\n",
    "    predict_song(model_rnn, temp, input_sequence, 400, builder)\n",
    "    print(\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T21:52:09.426539Z",
     "start_time": "2023-06-23T21:52:07.626389800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### GRU"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 2/150 [00:00<00:13, 11.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss 3.20066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 82/150 [00:07<00:06, 10.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 loss 0.01674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:14<00:00, 10.46it/s]\n"
     ]
    }
   ],
   "source": [
    "model_rnn = CharRNN(\"GRU\", builder.emb_dim, hidden_dim, hidden_layers, bidirectional).to(gpu)\n",
    "train(model_rnn, custom_dt, max_epochs, learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T21:52:23.796942800Z",
     "start_time": "2023-06-23T21:52:09.426539Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Varying the temperature"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----Temperature 0.2 ----\n",
      "\n",
      "più di un trip di sta miss mezza brasiliana!\n",
      "dita missa con he più quello che ho prozzara!\n",
      "più della missa mila si abana!\n",
      "più della coca\n",
      "sanana!\n",
      "più di un trip di sta miss mezza brasiliana!\n",
      "dita missa mita!\n",
      "si amezzababrilizana!\n",
      "più di un trip di sta miss mezzabana!\n",
      "più della coca\n",
      "sanana!\n",
      "più di un trip di sta miss mezza brasiliana!\n",
      "dita missa con he più quello che ho provei io cono!\n",
      "famminan bri\n",
      "\n",
      "----Temperature 0.5 ----\n",
      "\n",
      "più di un trip di sta miss mezza brasiliana!\n",
      "did di sun furta\n",
      "più della misagia!\n",
      "miù di un trip di sta miss mezza brasiliana!\n",
      "dita più di ogni banconota, più della coca\n",
      "sanana!\n",
      "più di un trip di sta miss mezza brasiliana!\n",
      "dita missa co ho proveie in cochota, più della coca\n",
      "sanana!\n",
      "più di un trip di sta miss mezzabana!\n",
      "più della coca\n",
      "più deila coca\n",
      "più deil si eilo co ho ta trita!\n",
      "si amelli cove!\n",
      "\n",
      "\n",
      "----Temperature 1.0 ----\n",
      "\n",
      "più di un trip di sta miss mezza brasiliana!\n",
      "dita picabana!\n",
      "più dello comedoka!\n",
      "più di un trip di sta miss mezza brasiliana!\n",
      "di un brivodo con ho più di ogni banconota, più della coca\n",
      "panana!\n",
      "più di un trip di sta miss mezza brasiliana!\n",
      "did di suta\n",
      "misio con ho più di ogni banconotaratranana\n",
      "cocafabana!\n",
      "came invo hito, ditu dita più quello dita suca\n",
      "più della siesana coca\n",
      "panana!\n",
      "più di un trip d\n",
      "\n",
      "----Temperature 1.2 ----\n",
      "\n",
      "più di un trip di d brilss a mita!\n",
      "miù di ogni banconota, più della coca\n",
      "sarcacaita!\n",
      "dita copacabana!\n",
      "(i sunto!\n",
      "furrbancato!\n",
      "sun mistammisiona!\n",
      "più di un trip di sta miss mezza brasiliana!\n",
      "dita, più di un rrovido, non on nrrodisio, non un bricodota!\n",
      "miù di un bripiù di o ril si e brità, co, si un reezzo co medda brizabana!\n",
      "di un ho suro!\n",
      "frimmmi banto so qucho si an cuche succavananana!\n",
      "più di un\n"
     ]
    }
   ],
   "source": [
    "for temp in [0.2, 0.5, 1.0, 1.2]:\n",
    "    print(f\"\\n----Temperature {temp} ----\")\n",
    "    predict_song(model_rnn, temp, input_sequence, 400, builder)\n",
    "    print(\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T21:52:25.178834200Z",
     "start_time": "2023-06-23T21:52:23.796942800Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
