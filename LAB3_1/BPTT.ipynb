{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from LAB3_1.bptt_neuralnetwork import RecurrentNeuralNetwork\n",
    "from LAB3_1.utils import Sequential_mnist, compute_acc,show_loss\n",
    "\n",
    "from numpy import linspace"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T16:10:31.930053800Z",
     "start_time": "2023-06-23T16:10:31.918733600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "tr_dataset = Sequential_mnist(\"train\")\n",
    "tr_x, tr_y = tr_dataset.data.numpy(), tr_dataset.target.numpy()\n",
    "idx_tr = np.hstack([np.where(tr_y == 0)[0],np.where(tr_y == 1)[0]])\n",
    "np.random.shuffle(idx_tr)\n",
    "tr_x, tr_y = tr_x[idx_tr], tr_y[idx_tr]\n",
    "\n",
    "\n",
    "vl_dataset = Sequential_mnist(\"dev\")\n",
    "vl_x, vl_y = vl_dataset.data.numpy(), vl_dataset.target.numpy()\n",
    "idx_vl = np.hstack([np.where(vl_y == 0)[0],np.where(vl_y == 1)[0]])\n",
    "np.random.shuffle(idx_vl)\n",
    "vl_x, vl_y = vl_x[idx_vl], vl_y[idx_vl]\n",
    "\n",
    "batch_size = 256\n",
    "batch_seq = linspace(0, tr_x.shape[0], int(tr_x.shape[0]/batch_size),dtype=int)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T16:10:32.141052100Z",
     "start_time": "2023-06-23T16:10:31.930053800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "rnn = RecurrentNeuralNetwork(1, 2, hidden_dim=5, lr=0.001, clip=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T16:10:32.161245600Z",
     "start_time": "2023-06-23T16:10:32.141052100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Batch 1/20 Loss 0.6912 Accuracy 0.5386\n",
      "Epoch 0 Batch 2/20 Loss 0.6915 Accuracy 0.5332\n",
      "Epoch 0 Batch 3/20 Loss 0.6911 Accuracy 0.5394\n",
      "Epoch 0 Batch 4/20 Loss 0.6908 Accuracy 0.544\n",
      "Epoch 0 Batch 5/20 Loss 0.6907 Accuracy 0.5466\n",
      "Epoch 0 Batch 6/20 Loss 0.6914 Accuracy 0.535\n",
      "Epoch 0 Batch 7/20 Loss 0.6913 Accuracy 0.5368\n",
      "Epoch 0 Batch 8/20 Loss 0.6939 Accuracy 0.4964\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[13], line 10\u001B[0m\n\u001B[0;32m      7\u001B[0m x \u001B[38;5;241m=\u001B[39m tr_x[batch_seq[b\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]:batch_seq[b]\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m      8\u001B[0m y \u001B[38;5;241m=\u001B[39m tr_y[batch_seq[b\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]:batch_seq[b]\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m---> 10\u001B[0m y_pred, loss \u001B[38;5;241m=\u001B[39m \u001B[43mrnn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     12\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mround\u001B[39m(loss\u001B[38;5;241m/\u001B[39mx\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;241m4\u001B[39m)\n\u001B[0;32m     13\u001B[0m acc \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mround\u001B[39m(compute_acc(y_pred, y), \u001B[38;5;241m4\u001B[39m)\n",
      "File \u001B[1;32mK:\\NoSyncProject\\Computational-NeuroScience-Lab\\LAB3_1\\bptt_neuralnetwork.py:95\u001B[0m, in \u001B[0;36mRecurrentNeuralNetwork.__call__\u001B[1;34m(self, x, y, h0)\u001B[0m\n\u001B[0;32m     93\u001B[0m     g_wx \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m tmp\u001B[38;5;241m.\u001B[39mT \u001B[38;5;241m@\u001B[39m x[:, i, :]\n\u001B[0;32m     94\u001B[0m     g_bh \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m tmp\u001B[38;5;241m.\u001B[39mT\u001B[38;5;241m.\u001B[39msum(axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, keepdims\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m---> 95\u001B[0m     tmp \u001B[38;5;241m=\u001B[39m (tmp \u001B[38;5;241m@\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mw_h\u001B[38;5;241m.\u001B[39mT) \u001B[38;5;241m*\u001B[39m (\u001B[43md_activ\u001B[49m\u001B[43m(\u001B[49m\u001B[43mz_stack\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m     96\u001B[0m \u001B[38;5;66;03m# ---------------- Backward ----------------\u001B[39;00m\n\u001B[0;32m     98\u001B[0m g_wx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclipping_grad(g_wx)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GeneralPurpose\\lib\\site-packages\\numpy\\lib\\function_base.py:2301\u001B[0m, in \u001B[0;36mvectorize.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2298\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   2299\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_in_and_out_core_dims \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 2301\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m   2302\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   2303\u001B[0m \u001B[38;5;124;03m    Return arrays with the results of `pyfunc` broadcast (vectorized) over\u001B[39;00m\n\u001B[0;32m   2304\u001B[0m \u001B[38;5;124;03m    `args` and `kwargs` not in `excluded`.\u001B[39;00m\n\u001B[0;32m   2305\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m   2306\u001B[0m     excluded \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexcluded\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "l_history,l_accuracy = [],[]\n",
    "\n",
    "nun_batches = len(batch_seq)\n",
    "for i in range(10):\n",
    "    for b in range(1, nun_batches):\n",
    "\n",
    "        x = tr_x[batch_seq[b-1]:batch_seq[b]-1]\n",
    "        y = tr_y[batch_seq[b-1]:batch_seq[b]-1]\n",
    "\n",
    "        y_pred, loss = rnn(x,y)\n",
    "\n",
    "        loss = round(loss/x.shape[0], 4)\n",
    "        acc = round(compute_acc(y_pred, y), 4)\n",
    "\n",
    "        l_history.append(loss)\n",
    "        l_accuracy.append(acc)\n",
    "\n",
    "        print(f\"Epoch {i} Batch {b}/{nun_batches} Loss {loss} Accuracy {acc}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T16:11:29.433483700Z",
     "start_time": "2023-06-23T16:10:32.161245600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "show_loss(l_history)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
