{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Bonus-Track Assignment 3: BackPropagation Through-Time algorithm from scratch\n",
    "\n",
    "Implement from scratch, e.g., with MATLAB or Numpy, the BackPropagation Through-Time algorithm for training an RNN to solve the above tasks on time-series. Notice that the BPTT derivation for the sequence transduction case (i.e., when you have an output at each input time-step, rather than an output at the end of the time-series) was left as an exercise."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# To work with Google colab\n",
    "#!wget https://raw.githubusercontent.com/jacons/Computational-NeuroScience-Lab/master/Utils/utils.py\n",
    "#!wget https://raw.githubusercontent.com/jacons/Computational-NeuroScience-Lab/master/LAB3_1/Assignment3/bptt_neuralnetwork.py\n",
    "\n",
    "from Utils.utils import Sequential_mnist, compute_acc, show_loss\n",
    "from LAB3_1.Assignment3.bptt_neuralnetwork import HandMadeRNN\n",
    "\n",
    "from numpy import linspace, arange"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-15T14:37:32.301957Z",
     "start_time": "2023-07-15T14:37:29.353872500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Retrieve Datasets and preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Get a training set-> return a Dataset class\n",
    "tr_dataset = Sequential_mnist(\"train\", root=\"..\\sources\\MNIST\")\n",
    "# take the effective data and the targets\n",
    "tr_x, tr_y = tr_dataset.data.numpy(), tr_dataset.target.numpy()\n",
    "# For simplicity, we take into consideration only 2 digits\n",
    "idx_tr = np.hstack([np.where(tr_y == 0)[0],np.where(tr_y == 1)[0]])\n",
    "np.random.shuffle(idx_tr) # we apply the Shuffling\n",
    "# select only the images that are as target 0 or 1\n",
    "tr_x, tr_y = tr_x[idx_tr], tr_y[idx_tr]\n",
    "\n",
    "# same preprocessing\n",
    "vl_dataset = Sequential_mnist(\"dev\", root=\"..\\sources\\MNIST\")\n",
    "vl_x, vl_y = vl_dataset.data.numpy(), vl_dataset.target.numpy()\n",
    "idx_vl = np.hstack([np.where(vl_y == 0)[0],np.where(vl_y == 1)[0]])\n",
    "np.random.shuffle(idx_vl)\n",
    "vl_x, vl_y = vl_x[idx_vl], vl_y[idx_vl]\n",
    "\n",
    "batch_size = 256\n",
    "batch_seq = linspace(0, tr_x.shape[0], int(tr_x.shape[0]/batch_size), dtype=int)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-15T14:37:32.498984400Z",
     "start_time": "2023-07-15T14:37:32.301957Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "rnn = HandMadeRNN(1, 2, hidden_dim=15, lr=0.001, clip=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-15T14:37:32.519245400Z",
     "start_time": "2023-07-15T14:37:32.500552500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Batch 1/41 Loss 0.6863 Accuracy 0.5606\n",
      "Epoch 0 Batch 2/41 Loss 0.689 Accuracy 0.5455\n",
      "Epoch 0 Batch 3/41 Loss 0.6877 Accuracy 0.553\n",
      "Epoch 0 Batch 4/41 Loss 0.6894 Accuracy 0.5434\n",
      "Epoch 0 Batch 5/41 Loss 0.6924 Accuracy 0.5265\n",
      "Epoch 0 Batch 6/41 Loss 0.6904 Accuracy 0.5379\n",
      "Epoch 0 Batch 7/41 Loss 0.6897 Accuracy 0.5417\n",
      "Epoch 0 Batch 8/41 Loss 0.6901 Accuracy 0.5396\n",
      "Epoch 0 Batch 9/41 Loss 0.6849 Accuracy 0.5682\n",
      "Epoch 0 Batch 10/41 Loss 0.6945 Accuracy 0.5152\n",
      "Epoch 0 Batch 11/41 Loss 0.689 Accuracy 0.5455\n",
      "Epoch 0 Batch 12/41 Loss 0.6928 Accuracy 0.5245\n",
      "Epoch 0 Batch 13/41 Loss 0.6917 Accuracy 0.5303\n",
      "Epoch 0 Batch 14/41 Loss 0.6849 Accuracy 0.5682\n",
      "Epoch 0 Batch 15/41 Loss 0.687 Accuracy 0.5568\n",
      "Epoch 0 Batch 16/41 Loss 0.6955 Accuracy 0.5094\n",
      "Epoch 0 Batch 17/41 Loss 0.6842 Accuracy 0.572\n",
      "Epoch 0 Batch 18/41 Loss 0.6883 Accuracy 0.5492\n",
      "Epoch 0 Batch 19/41 Loss 0.6897 Accuracy 0.5417\n",
      "Epoch 0 Batch 20/41 Loss 0.6962 Accuracy 0.5057\n",
      "Epoch 0 Batch 21/41 Loss 0.7 Accuracy 0.4848\n",
      "Epoch 0 Batch 22/41 Loss 0.7034 Accuracy 0.4659\n",
      "Epoch 0 Batch 23/41 Loss 0.6952 Accuracy 0.5114\n",
      "Epoch 0 Batch 24/41 Loss 0.686 Accuracy 0.5623\n",
      "Epoch 0 Batch 25/41 Loss 0.6945 Accuracy 0.5152\n",
      "Epoch 0 Batch 26/41 Loss 0.6788 Accuracy 0.6023\n",
      "Epoch 0 Batch 27/41 Loss 0.6876 Accuracy 0.553\n",
      "Epoch 0 Batch 28/41 Loss 0.6894 Accuracy 0.5434\n",
      "Epoch 0 Batch 29/41 Loss 0.6904 Accuracy 0.5379\n",
      "Epoch 0 Batch 30/41 Loss 0.6924 Accuracy 0.5265\n",
      "Epoch 0 Batch 31/41 Loss 0.6959 Accuracy 0.5076\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 10\u001B[0m\n\u001B[0;32m      7\u001B[0m x \u001B[38;5;241m=\u001B[39m tr_x[batch_seq[b\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]:batch_seq[b]\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m      8\u001B[0m y \u001B[38;5;241m=\u001B[39m tr_y[batch_seq[b\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]:batch_seq[b]\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m---> 10\u001B[0m y_pred, loss \u001B[38;5;241m=\u001B[39m \u001B[43mrnn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     12\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mround\u001B[39m(loss\u001B[38;5;241m/\u001B[39mx\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;241m4\u001B[39m)\n\u001B[0;32m     13\u001B[0m acc \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mround\u001B[39m(compute_acc(y_pred, y), \u001B[38;5;241m4\u001B[39m)\n",
      "File \u001B[1;32mK:\\NoSyncProject\\Computational-NeuroScience-Lab\\LAB3_1\\Assignment3\\bptt_neuralnetwork.py:94\u001B[0m, in \u001B[0;36mHandMadeRNN.__call__\u001B[1;34m(self, x, y, h0)\u001B[0m\n\u001B[0;32m     92\u001B[0m     g_wx \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m tmp\u001B[38;5;241m.\u001B[39mT \u001B[38;5;241m@\u001B[39m x[:, i, :]\n\u001B[0;32m     93\u001B[0m     g_bh \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m tmp\u001B[38;5;241m.\u001B[39mT\u001B[38;5;241m.\u001B[39msum(axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, keepdims\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m---> 94\u001B[0m     tmp \u001B[38;5;241m=\u001B[39m (tmp \u001B[38;5;241m@\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mw_h\u001B[38;5;241m.\u001B[39mT) \u001B[38;5;241m*\u001B[39m (\u001B[43md_activ\u001B[49m\u001B[43m(\u001B[49m\u001B[43mz_stack\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m     95\u001B[0m \u001B[38;5;66;03m# ---------------- Backward ----------------\u001B[39;00m\n\u001B[0;32m     97\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mw_x \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgrad_step(g_wx)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GeneralPurpose\\lib\\site-packages\\numpy\\lib\\function_base.py:2372\u001B[0m, in \u001B[0;36mvectorize.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2369\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_stage_2(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   2370\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n\u001B[1;32m-> 2372\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_as_normal(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GeneralPurpose\\lib\\site-packages\\numpy\\lib\\function_base.py:2365\u001B[0m, in \u001B[0;36mvectorize._call_as_normal\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2362\u001B[0m     vargs \u001B[38;5;241m=\u001B[39m [args[_i] \u001B[38;5;28;01mfor\u001B[39;00m _i \u001B[38;5;129;01min\u001B[39;00m inds]\n\u001B[0;32m   2363\u001B[0m     vargs\u001B[38;5;241m.\u001B[39mextend([kwargs[_n] \u001B[38;5;28;01mfor\u001B[39;00m _n \u001B[38;5;129;01min\u001B[39;00m names])\n\u001B[1;32m-> 2365\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_vectorize_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GeneralPurpose\\lib\\site-packages\\numpy\\lib\\function_base.py:2455\u001B[0m, in \u001B[0;36mvectorize._vectorize_call\u001B[1;34m(self, func, args)\u001B[0m\n\u001B[0;32m   2452\u001B[0m \u001B[38;5;66;03m# Convert args to object arrays first\u001B[39;00m\n\u001B[0;32m   2453\u001B[0m inputs \u001B[38;5;241m=\u001B[39m [asanyarray(a, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mobject\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m a \u001B[38;5;129;01min\u001B[39;00m args]\n\u001B[1;32m-> 2455\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mufunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2457\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ufunc\u001B[38;5;241m.\u001B[39mnout \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   2458\u001B[0m     res \u001B[38;5;241m=\u001B[39m asanyarray(outputs, dtype\u001B[38;5;241m=\u001B[39motypes[\u001B[38;5;241m0\u001B[39m])\n",
      "File \u001B[1;32mK:\\NoSyncProject\\Computational-NeuroScience-Lab\\LAB3_1\\Assignment3\\bptt_neuralnetwork.py:79\u001B[0m, in \u001B[0;36mHandMadeRNN.__call__.<locals>.<lambda>\u001B[1;34m(x_)\u001B[0m\n\u001B[0;32m     76\u001B[0m g_wx \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros_like(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mw_x)\n\u001B[0;32m     77\u001B[0m g_bh \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros_like(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mb_h)\n\u001B[1;32m---> 79\u001B[0m d_activ \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mvectorize(\u001B[38;5;28;01mlambda\u001B[39;00m x_: \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m np\u001B[38;5;241m.\u001B[39mpower(np\u001B[38;5;241m.\u001B[39mtanh(x_), \u001B[38;5;241m2\u001B[39m))\n\u001B[0;32m     81\u001B[0m \u001B[38;5;66;03m# ---------------- Backward ----------------\u001B[39;00m\n\u001B[0;32m     82\u001B[0m \u001B[38;5;66;03m# Take only the last hidden state and apply the softmax return a distribution of probability\u001B[39;00m\n\u001B[0;32m     83\u001B[0m loss \u001B[38;5;241m=\u001B[39m CELoss(y_pred, y)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "l_history,l_accuracy = [],[]\n",
    "\n",
    "nun_batches = len(batch_seq)\n",
    "for i in range(10):\n",
    "    for b in range(1, nun_batches):\n",
    "\n",
    "        x = tr_x[batch_seq[b-1]:batch_seq[b]-1]\n",
    "        y = tr_y[batch_seq[b-1]:batch_seq[b]-1]\n",
    "\n",
    "        y_pred, loss = rnn(x,y)\n",
    "\n",
    "        loss = round(loss/x.shape[0], 4)\n",
    "        acc = round(compute_acc(y_pred, y), 4)\n",
    "\n",
    "        l_history.append(loss)\n",
    "        l_accuracy.append(acc)\n",
    "\n",
    "        print(f\"Epoch {i} Batch {b}/{nun_batches} Loss {loss} Accuracy {acc}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-15T14:42:41.309639700Z",
     "start_time": "2023-07-15T14:37:32.519245400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "show_loss(l_history)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
