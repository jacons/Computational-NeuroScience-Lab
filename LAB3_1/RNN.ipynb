{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import copy\n",
    "import sys\n",
    "\n",
    "from LAB3_1.utils import show_loss, show_result\n",
    "\n",
    "from tqdm import tqdm\n",
    "from typing import Tuple\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch import Tensor, no_grad, zeros\n",
    "from torch.nn import Module, Sequential, Linear, MSELoss, ReLU, RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Retrieve the dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gpu = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "source1 = pd.read_csv(\"./sources/NARMA10.csv\", header=None).T.to_numpy()\n",
    "source2 = pd.read_csv(\"./sources/MG17.csv\", header=None).T.to_numpy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hold-out"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "source1 = np.expand_dims(source1.T, axis=-1)\n",
    "tr_dataset, dev_dataset, ts_dataset = source1[:,:4000], source1[:,4000:5000], source1[:,5000:]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Recurrent Neural network\n",
    "class RecurrentNN(Module):\n",
    "    def __init__(self, hidden:int, layers:int, no_linearity:str=\"relu\"):\n",
    "        super(RecurrentNN,self).__init__()\n",
    "        self.hidden_size = hidden\n",
    "        self.layers = layers\n",
    "\n",
    "        self.rnn = RNN(input_size=1,\n",
    "                       hidden_size=hidden,\n",
    "                       num_layers=layers,\n",
    "                       nonlinearity=no_linearity,\n",
    "                       batch_first=True)\n",
    "\n",
    "        self.read_out = Sequential(ReLU(), Linear(hidden, 1))\n",
    "        self.criteria = MSELoss() # Mean square error loss\n",
    "\n",
    "        self.last_hidden = None\n",
    "\n",
    "    def forward(self, x:Tensor, y:Tensor=None, save_state:bool=False):\n",
    "        # input [steps,1]\n",
    "        # output [step, hidden], hn [layer,hidden]\n",
    "        output, hn = self.rnn(x, self.last_hidden)\n",
    "        y_pred = self.read_out(output) # we take the last step\n",
    "\n",
    "        if save_state:\n",
    "            self.last_hidden = hn.detach()\n",
    "\n",
    "        loss = None\n",
    "        if y is not None:\n",
    "            loss = self.criteria(y_pred, y)\n",
    "        return (loss, y_pred) if loss is not None else y_pred"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class RNN_trainer:\n",
    "    def __init__(self, hidden:int, layers:int, no_linearity:str):\n",
    "\n",
    "        # model\n",
    "        self.model = RecurrentNN(hidden=hidden, layers=layers, no_linearity=no_linearity).to(gpu)\n",
    "\n",
    "    def fit(self, df:ndarray, epochs:int=2, lr:float=0.001)->Tensor:\n",
    "        df = torch.from_numpy(df).float().to(gpu)\n",
    "\n",
    "        # Oss. we avoid implementing further mechanisms like early stopping, scheduler, ecc.\n",
    "        opt = Adam(self.model.parameters(), lr)\n",
    "        history_tr = zeros(epochs)\n",
    "        self.model.train()\n",
    "\n",
    "        for i in range(epochs):\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "\n",
    "            loss = self.model(df[0], df[1])[0] # perform the output\n",
    "            loss.backward() # gradient accumulation\n",
    "\n",
    "            opt.step()\n",
    "\n",
    "            # save the current loss\n",
    "            history_tr[i] = loss.item()\n",
    "\n",
    "        return history_tr\n",
    "\n",
    "    def validate(self, df:ndarray, save_state:bool=False) -> Tuple:\n",
    "        df = torch.from_numpy(df).float().to(gpu)\n",
    "\n",
    "        return  self.predict(df[0], df[1], save_state) + (df[1],)\n",
    "\n",
    "    def predict(self, x:Tensor, y:Tensor=None, save_state:bool=False):\n",
    "        \"\"\"\n",
    "        If the target it is provided, the method performs also the loss, otherwise\n",
    "        return only the output of the network.\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        with no_grad():\n",
    "            return  self.model(x, y, save_state) # perform the output\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ranges_to_explore = {\n",
    "    \"units\" : [100, 200, 500],\n",
    "    \"epochs\" : [500, 800],\n",
    "    \"lr\" : [0.003, 0.008, 0.01],\n",
    "    \"layers\": [1],\n",
    "    \"activ\" : [\"relu\"]\n",
    "}\n",
    "\n",
    "class GridSearch:\n",
    "\n",
    "    def __init__(self, tr:ndarray, dev:ndarray):\n",
    "\n",
    "        all_configs = [dict(zip(ranges_to_explore.keys(), configs)) for configs in product(*ranges_to_explore.values())]\n",
    "\n",
    "        print(\"Number of configurations to try: \",len(all_configs))\n",
    "        # returns the performance in each configuration, the best model and the history of the loss\n",
    "        rank, best, loss = self.run(tr, dev, all_configs)\n",
    "\n",
    "        # we sort by validation loss\n",
    "        rank = sorted(rank, key=lambda conf: conf[2])\n",
    "\n",
    "        print(\"\\nThe best solution in \", rank[0])\n",
    "        self.best_config = rank[0][0]\n",
    "        self.best_model = best\n",
    "        self.tr_loss = loss\n",
    "\n",
    "    @staticmethod\n",
    "    def run(tr:ndarray, dev:ndarray, configs:list):\n",
    "        \"\"\"\n",
    "        In the grid search, we explore all configurations provided and try to find the best\n",
    "        hyperparameter configuration using the training set to train the model and the validation\n",
    "        set to compare the performance among all models instantiated by configurations.\n",
    "        \"\"\"\n",
    "\n",
    "        rank = [] # the keep in track the configuration and the corresponding performance\n",
    "\n",
    "        # we save the best trained model and the training loss during the epochs\n",
    "        best, loss = None, None\n",
    "        best_dev_loss = sys.maxsize\n",
    "\n",
    "        for config in tqdm(configs):\n",
    "\n",
    "            trainer = RNN_trainer(hidden=config[\"units\"],\n",
    "                                  layers=config[\"layers\"],\n",
    "                                  no_linearity=config[\"activ\"])\n",
    "\n",
    "            history = trainer.fit(tr, config[\"epochs\"], config[\"lr\"])\n",
    "            vl_loss = trainer.validate(dev)[0].item()\n",
    "\n",
    "            rank.append((config, round(history[-1].item(), 6), round(vl_loss, 6)))\n",
    "\n",
    "            # we keep the best model\n",
    "            if best_dev_loss > vl_loss:\n",
    "                best_dev_loss = vl_loss\n",
    "                loss = copy.deepcopy(history)\n",
    "                best = copy.deepcopy(trainer)\n",
    "\n",
    "        return rank, best, loss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Assignment 1.1: NARMA10 task with RNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gs = GridSearch(tr_dataset, dev_dataset)\n",
    "best_config =  gs.best_config\n",
    "best_model = gs.best_model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training loss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "show_loss(gs.tr_loss)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train, Validation and Test errors in the best configuration"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tr_loss = best_model.validate(tr_dataset, save_state=True)[0]\n",
    "print(\"Train Error\", round(tr_loss.item(), 6))\n",
    "\n",
    "dev_loss = best_model.validate(dev_dataset)[0]\n",
    "print(\"Validation Error\", round(dev_loss.item(), 6))\n",
    "\n",
    "test_loss = best_model.validate(ts_dataset)[0]\n",
    "print(\"Test Error\", round(test_loss.item(), 6))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Final retrain with Training and Validation set (with the best configuration)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "final_trainer = RNN_trainer(hidden=best_config[\"units\"],\n",
    "                            layers=best_config[\"layers\"],\n",
    "                            no_linearity=best_config[\"activ\"])\n",
    "# we use both training and validation as a training set, using the best parameters\n",
    "# found in the previous model selection\n",
    "final_tr = np.hstack([tr_dataset, dev_dataset])\n",
    "tr_history = final_trainer.fit(final_tr, best_config[\"epochs\"], lr=best_config[\"lr\"])\n",
    "\n",
    "tr_loss, tr_out, tr_y = final_trainer.validate(final_tr)\n",
    "print(\"Validation Error\", round(tr_loss.item(), 6))\n",
    "\n",
    "test_loss, test_out, test_y  = final_trainer.validate(ts_dataset)\n",
    "print(\"Test Error\", round(test_loss.item(), 6))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "show_loss(tr_history)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "show_result(tr_out.cpu(), tr_y.cpu(), test_out.cpu(), test_y.cpu())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bonus-track Assignment 1: Mackey-Glass 17 task with RNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hold out"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "source_aligned = np.zeros((2, source2.shape[0]-1, 1))\n",
    "source_aligned[0], source_aligned[1] = source2[:-1], source2[1:]\n",
    "tr_dataset, dev_dataset, ts_dataset = source_aligned[:,:4000], source_aligned[:,4000:5000], source_aligned[:,5000:]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gs = GridSearch(tr_dataset, dev_dataset)\n",
    "best_config =  gs.best_config\n",
    "best_model = gs.best_model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training loss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "show_loss(gs.tr_loss)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train, Validation and Test errors in the best configuration"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tr_loss = best_model.validate(tr_dataset, save_state=True)[0]\n",
    "print(\"Train Error\", round(tr_loss.item(), 6))\n",
    "\n",
    "dev_loss = best_model.validate(dev_dataset)[0]\n",
    "print(\"Validation Error\", round(dev_loss.item(), 6))\n",
    "\n",
    "test_loss = best_model.validate(ts_dataset)[0]\n",
    "print(\"Test Error\", round(test_loss.item(), 6))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Final retrain with Training and Validation set (with the best configuration)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "final_trainer = RNN_trainer(hidden=best_config[\"units\"],\n",
    "                            layers=best_config[\"layers\"],\n",
    "                            no_linearity=best_config[\"activ\"])\n",
    "# we use both training and validation as a training set, using the best parameters\n",
    "# found in the previous model selection\n",
    "final_tr = np.hstack([tr_dataset, dev_dataset])\n",
    "tr_history = final_trainer.fit(final_tr, best_config[\"epochs\"], lr=best_config[\"lr\"])\n",
    "\n",
    "tr_loss, tr_out, tr_y = final_trainer.validate(final_tr)\n",
    "print(\"Validation Error\", round(tr_loss.item(), 6))\n",
    "\n",
    "test_loss, test_out, test_y  = final_trainer.validate(ts_dataset)\n",
    "print(\"Test Error\", round(test_loss.item(), 6))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "show_loss(tr_history)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "show_result(tr_out.cpu(), tr_y.cpu(), test_out.cpu(), test_y.cpu())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torch import nn\n",
    "#\n",
    "# rnn = nn.RNN(1, 20, 1, batch_first=True) # x , hidden-node , layer\n",
    "# read_out = nn.Linear(20,1) # hidden-node , out-size\n",
    "#\n",
    "# input = torch.randn(3000, 1) # steps, dim_x\n",
    "# output, hn = rnn(input)\n",
    "# print(output.shape, hn.shape)\n",
    "# output = read_out(output)\n",
    "# print(output.shape, hn.shape)\n",
    "#\n",
    "#\n",
    "# print(read_out(output).shape)\n",
    "#\n",
    "# print(h0.shape)\n",
    "# print(output.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
